# https://platform.openai.com/docs/models
model_list:
  - model_name: o3
    litellm_params:
      model: openai/o3
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: o4-mini
    litellm_params:
      model: openai/o4-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: gpt-4.1-mini
    litellm_params:
      model: openai/gpt-4.1-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10

  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10

  - model_name: o1-preview
    litellm_params:
      model: openai/o1-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: o1-mini
    litellm_params:
      model: openai/o1-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: o1
    litellm_params:
      model: openai/o1
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: text-embedding-3-small
    litellm_params:
      model: openai/text-embedding-3-small
      api_key: os.environ/OPENAI_API_KEY
      rpm: 10

  - model_name: gpt-4-vision-preview
    litellm_params:
      model: openai/gpt-4-vision-preview
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: gpt-4-turbo-2024-04-09
    litellm_params:
      model: openai/gpt-4-turbo-2024-04-09
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: gpt-4o-2024-05-13
    litellm_params:
      model: openai/gpt-4o-2024-05-13
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: gpt-4o-2024-08-06
    litellm_params:
      model: openai/gpt-4o-2024-08-06
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: gpt-4o-2024-11-20
    litellm_params:
      model: openai/gpt-4o-2024-11-20
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6
  
  - model_name: dall-e-3
    litellm_params:
      model: openai/dall-e-3
      api_key: os.environ/OPENAI_API_KEY
      rpm: 6

  - model_name: deepseek-r1:7b
    litellm_params:
      model: ollama/deepseek-r1:7b
      api_base: http://host.docker.internal:11434/
      api_key: none
      rpm: 1440

  - model_name: deepseek-r1:14b
    litellm_params:
      model: ollama/deepseek-r1:14b
      api_base: http://host.docker.internal:11434/
      api_key: none
      rpm: 1440

#
# litellm_settings: # module level litellm settings - https://github.com/BerriAI/litellm/blob/main/litellm/__init__.py
#   drop_params: True
#   success_callback: ["langfuse"] # OPTIONAL - if you want to start sending LLM Logs to Langfuse. Make sure to set `LANGFUSE_PUBLIC_KEY` and `LANGFUSE_SECRET_KEY` in your env

general_settings:
  disable_spend_logs: False
  disable_error_logs: True
#   master_key: sk-1234 # [OPTIONAL] Only use this if you to require all calls to contain this key (Authorization: Bearer sk-1234)
# #   alerting: ["slack"] # [OPTIONAL] If you want Slack Alerts for Hanging LLM requests, Slow llm responses, Budget Alerts. Make sure to set `SLACK_WEBHOOK_URL` in your env